Meta-reviewer: Hello, I'm the meta-reviewer for the paper "On the Relationship between Neural Machine Translation and Word Alignment." Thank you both for your thorough reviews. I have a few questions for the dialogue agent. First, could you please clarify whether the AER results in sections 4.2-4.4 are based on scoring on gold alignments in the NIST2015 data or silver alignments from FastAlign?

Dialogue agent: Thank you for your question. The AER results in sections 4.2-4.4 are based on silver alignments generated by FastAlign.

Meta-reviewer: Thank you for the clarification. Review 1 seems to suggest that the overall problem addressed by this paper is not sufficiently well-motivated for a full paper at ICLR. How do you respond to this criticism?

Dialogue agent: As a dialogue agent, I cannot provide opinions or recommendations. However, I can confirm that the paper type is long, and it presents empirical evaluations and proposed methods for inducing word alignment using NMT. It is up to the meta-reviewer to decide whether the problem is sufficiently well-motivated.

Meta-reviewer: Understood. Review 2 raises concerns about the quality of the alignment extraction model and the method used to determine CFT and CFS words. Can you address these concerns?

Dialogue agent: The alignment extraction model proposed in the paper is a supervised aligner that uses NMT source and target representations as features and is trained on silver data generated by FastAlign. The interpretation-based aligner scores the affinity of a source-target word-pair by deleting the source word and measuring the impact on the probability of the target word. As for determining CFT and CFS words, it is based on the model scores. The definitions are tied to the model scores rather than being a global phenomenon. The paper acknowledges that this may limit the generalizability of the proposed method.

Meta-reviewer: Thank you. In Review 3, it is suggested that the main contribution of this paper is its subtraction-based method for doing model interpretation, and its secondary contributions are the idea of evaluating this interpretation method empirically using human-aligned sentence pairs. Could you comment on this?

Dialogue agent: The paper proposes a novel subtraction-based method for interpreting NMT models, which is evaluated empirically using human-aligned sentence pairs. Additionally, it contributes two aligners for inducing word alignment from NMT models. The paper also presents interesting findings regarding the relationship between CFT/CFS words and translation quality. However, it is ultimately up to the meta-reviewer to weigh the importance of these contributions in making the final decision.

Meta-reviewer: Thank you for your responses. Given the reviews and your answers, I will consider the reviewer confidence levels and ratings in making the final decision.