Meta-reviewer:Hello, dialogue agent. Can you tell me about the paper's reviews and what they say regarding the paper's content and contribution?

Dialogue Agent: Sure. Review 1 states that the paper extends an existing approach to adaptive softmax classifiers used for the output component of neural language models into the input component and that the approach is incremental but significant in the language modeling architecture space. The review also mentions that the perplexity results bear out the advantages of combining adaptively-sized representations with weight tying. The reviewer suggests that a comparison with Merity et al.'s approach is missing. They also suggest that the discussion/explanation of the differing performance of tying or not tying each part of the embedding weights for the different datasets is confusing. The loss by frequency-bin plots receive high praise for clarity. Although the full-softmax BPE approach is worse than the adaptive softmax word level. Reviewer 2 praises the paper for introducing a new architecture for input embeddings that allows a model builder to define a set of bands of input words with different frequency. The embeddings of each band are then projected into the same size, lowering the number of parameters. The paper shows that ADP gained performance across all word frequency ranges. Despite the weight sharing needing further investigation, the experiments support the claim. The runtime of ADP seemed to lose in terms of scaling as well to BPE, which could be an artifact of multi-GPU training. Reviewer 3 finds the article well-written and the contribution simple but interesting. They recommend that the small-sized embeddings are not made richer when backprojected to R^d, thereby keeping the original variable-size embeddings.

Meta-reviewer: Based on these reviews, what is your opinion on the paper and its contribution?

Dialogue Agent: I cannot provide opinions or recommendations. However, I can tell you that Reviewer 1 scores the paper 7 (Good paper, accept) and is confident but not absolutely certain that the evaluation is correct. Reviewer 2 scores the paper 8 (Top 50% of accepted papers, clear accept), and like Reviewer 1, is also confident but not absolutely certain that the evaluation is correct. Reviewer 3 scores the paper 8 (Top 50% of accepted papers, clear accept), and like Reviewer 1 and 2, is confident but not absolutely certain that the evaluation is correct.