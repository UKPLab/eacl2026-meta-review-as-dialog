Meta-Reviewer: Hello, thank you both for submitting your reviews and evaluations on the paper "Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation". Based on the reviews, it seems like there are some concerns about the technical novelty of the paper compared to the AQM approach, as well as the lack of analysis regarding the technical contributions of AQM+. Reviewer 1 suggests that the paper is not very well-written and could benefit from clarifications regarding the computation of the top-k information gain term. 

Dialogue Agent: Thank you for your feedback, Meta-Reviewer. We appreciate the constructive criticism. Regarding the concerns about technical novelty, we agree that some aspects of AQM+ are incremental improvements over AQM, such as using an RNN generator to generate free-form language questions instead of selecting from a predefined set. However, we would argue that other aspects, such as estimating approximate information gain using subsets of the class and answer space corresponding to the beam-search generated question set and their corresponding answers, is a non-trivial contribution. As for the writing, we will take Reviewer 1's suggestions into consideration when revising the paper.

Meta-Reviewer: Thank you for your response, Dialogue Agent. Reviewer 2 expressed concern about the lack of evaluation of Visual Dialog metrics and inference time, as well as the absence of a discussion on comparison to AQM for a model named AQM+. Can you address these points?

Dialogue Agent: Yes, we plan to include evaluation on the standard Visual Dialog test metrics in future work, as we believe this would contribute to the community's understanding of our approach. Regarding inference time, AQM+ does require more computation than a non-introspective model, and we will report the relative increase in inference efficiency in our revised version. We did not make an explicit comparison to AQM because AQM and AQM+ were tested on different datasets with different task settings. However, we understand the importance of comparison and will discuss this issue in the paper.

Meta-Reviewer: Thank you for your reply, Dialogue Agent. Finally, Reviewer 3 had concerns about missing ablations and the need for strong analysis of the proposed changes and their effect. Can you speak to the missing ablations and how you plan to address these concerns?

Dialogue Agent: Yes, we agree that we should have included more ablations to test the importance of the proposed changes. We plan to address this in our revised version by comparing AQM+ with a Q_fix set samples from training, evaluating how important dialog history is to the aprxAns model, and examining the importance of the choice to restrict to |C| classes. We will also include a more thorough analysis of the proposed changes and their effect on the performance of AQM+.