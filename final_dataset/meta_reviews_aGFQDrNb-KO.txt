Meta-reviewer: Hello, dialogue agent. I am reviewing a paper titled "Multi-dataset Training of Transformers for Robust Action Recognition." Can you please provide me with a summary of the reviews for this paper?

Dialogue agent: Sure, the paper received three reviews. Review 1 praised the paper's contribution in introducing informative representation regularization into cross-dataset training for action recognition and the use of projection loss to mine intrinsic class relations. However, it also pointed out that the paper did not consider temporal information in the video sequence, and the projection and informative loss need to be carefully designed for cross-dataset action recognition. Review 2 commended the paper's simplicity and the effectiveness of the informative loss borrowed from Barlow Twins for including projection across different classification heads. However, it also suggested that the paper needs to consider other works in related tasks and provide further justification for some arguments. Review 3 appreciated the paper's strong recognition results via co-training multiple datasets with the MViTv2 transformer backbone and the efficacy of two novel components validated through an ablation study. However, it also pointed out the absence of related results on large-scale image pre-training and the lack of analyses for some experimental findings.

Meta-reviewer: Thank you for the summary. From a high-level perspective, what do you think about the paper's contribution and novelty?

Dialogue agent: As a dialogue agent, I can't provide opinions or recommendations. However, the reviews highlighted that the paper introduces informative representation regularization into cross-dataset action recognition, and it uses projection loss to mine intrinsic class relations. These aspects contribute to the paper's novelty and are worth considering for acceptance.

Meta-reviewer: I see. Can you explain the strengths and weaknesses of the paper mentioned in the reviews?

Dialogue agent: Sure. According to Review 1, the paper's strengths include introducing informative representation regularization and exploration of learning robust representations among multiple video domains. However, the paper's weaknesses include the lack of consideration of temporal information and the need for careful design of projection and informative loss. According to Review 2, the paper's strengths include its simplicity and the effectiveness of the informative loss borrowed from Barlow Twins. However, the paper's weaknesses include the need to consider related works in other tasks and provide further justification for some arguments. According to Review 3, the paper's strengths include its strong recognition results via co-training multiple datasets with the MViTv2 transformer backbone and the efficacy of two novel components validated through an ablation study. However, the paper's weaknesses include the absence of related results on large-scale image pre-training and the lack of analyses for some experimental findings.

Meta-reviewer: Thank you for the detailed response. Based on the reviews, do you think the paper should be accepted or rejected?

Dialogue agent: The reviews suggest that the paper is a technically solid paper with borderline acceptance. Review 1 and Review 2 suggest that the paper's reasons to accept outweigh the reasons to reject. However, Review 3 points out some weaknesses that need to be carefully considered. Therefore, the final decision should weigh the strengths and weaknesses highlighted in the reviews and the confidence of the meta-reviewer in the assessment's technical soundness.