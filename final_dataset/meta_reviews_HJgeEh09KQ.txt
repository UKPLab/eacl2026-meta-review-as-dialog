Meta-reviewer: Hello, dialogue agent. I have received three reviews for the paper "Boosting Robustness Certification of Neural Networks" and I need your assistance in making a decision whether to accept or reject the paper. Can you provide me with some information about the paper and its reviews?

Dialogue agent: Certainly. "Boosting Robustness Certification of Neural Networks" is a long paper that proposes a mixed strategy for obtaining better precision on robustness verifications of feed-forward neural networks with piecewise linear activation functions. The proposed approach combines complete yet expensive methods based on mixed integer-linear programming (MILP) and incomplete yet cheap methods based on abstract interpretation or linear-programming relaxation. The reviews are as follows:

- Review 1 rates the paper as marginally below acceptance threshold. The reviewer is confident but not absolutely certain that the evaluation is correct. They find the paper well-written but raise some concerns about the experiments, particularly about comparisons with other complete and incomplete verifiers and scalability to other datasets. They also ask about the paper's ability to handle non-piecewise linear activation functions and the effect of neural selection heuristics.
- Review 2 rates the paper as marginally above acceptance threshold. The reviewer is fairly confident that the evaluation is correct. They find the paper's approach novel and interesting, but raise some concerns about experimental justifications, particularly about MILP-based refinement and the need for more datasets and networks to be tried. They also ask about some notations and explanations in the paper.
- Review 3 rates the paper as ok but not good enough for acceptance and the reviewer is fairly confident that the evaluation is correct. They find the paper well-written but lack reasoning and justification about the proposed techniques. They also ask for more extensive experimental results.

Meta-reviewer: Thank you for the summary. I find the paper's approach interesting and well-written as the reviewers have noted. However, I share some of their concerns, particularly about the comparisons with other verifiers and the need for more extensive experimental results. Since the paper is marginally below acceptance threshold based on Review 1, I would like to know more about the experiments and comparisons with other verifiers.

Dialogue agent: The paper's experiments compare verified robustness with AI2 and show that RefineAI can verify more than AI2 at the expense of much more computation time. However, Review 1 asks how RefineAI or AI2 compares with other complete and incomplete verifiers as described in the second paragraph of the introduction. The AI2 does not seem to have public available codes that readers can try out, but for some complete and incomplete verifiers papers mentioned in the introductions, there are some public codes available. The reviewer asks how Refine AI proposed in this paper compares with the above four papers in terms of the verified robustness percentage on the test set, the robustness bound, and the runtime.

Meta-reviewer: That's helpful. Can you also clarify whether the paper can handle non-piecewise linear activation functions and what effect neural selection heuristics have on the output bounds?

Dialogue agent: Review 1 asks whether RefineAI can handle only piece-wise linear activation functions and how it can handle other non-piece-wise linear activation functions. Also, they ask how tight the output bounds are improved by the neuron selection heuristics.

Meta-reviewer: Thank you for the answers. These clarifications are helpful for making an informed decision.