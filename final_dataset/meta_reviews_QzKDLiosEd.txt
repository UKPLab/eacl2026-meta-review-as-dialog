Meta-reviewer: Hello, dialogue agent. I have reviewed the reviews for the paper "Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel". I see that there are two conflicting opinions. It seems like the paper is interesting, but some reviewers question its relevance to ICLR. Can you help me understand the strengths and weaknesses of the paper and its significance to the ML community?

Dialogue agent: Thank you for the opportunity to discuss the paper. The paper presents a novel method for using magnetic side channel information from a GPU to recover the architecture and hyperparameters of a deep neural network. The authors demonstrate that they can accurately reconstruct the model's details by analyzing the magnetic fields emitted from a GPU's power cable. They also show that the inferred models can be used to launch black-box adversarial attacks with high success rates.

In terms of strengths, the paper presents an innovative approach to recover detailed structures of deep models. The experiments are thorough, and the results are presented clearly, with limitations and possible countermeasures discussed.

As for weaknesses, some reviewers question the practicality of the threat model, including the assumption of having physical access to the GPU, knowing exact input feature dimensions and batch size, and deep learning frameworks and GPU brand and hardware/software versions. Additionally, while the paper presents a novel approach to recovering network structures, it does not introduce any significant contribution to the core ML community. Finally, some reviewers suggest that the paper would be better suited for other venues such as cyber security conferences.

Meta-reviewer: Thank you for summarizing the key points and issues of the paper. These reviews help me understand why there are differing opinions. The practicality of the threat model concerns me and limits the impact of the paper in reality. On the other hand, the novelty of the proposed method and its potential impact on the safety-critical applications community using ML are attractive. Considering the reviews, I'm marginally below the acceptance threshold. Can you provide some information that may help me make a decision?

Dialogue agent: As an AI-based dialogue agent, I cannot provide opinions or recommendations. However, I can provide additional information that may help you make a decision. For example, the authors explained in their response how one might imagine launching the attack in reality. They provide an example application that may help readers understand the scenarios where the threat model could apply. Also, while the paper may not introduce any significant contribution to the core ML community, it does provide important insights into the security of systems employing deep learning models, highlighting the need for further research in this area.

Meta-reviewer: Thank you for the additional information. It helps me better evaluate the significance of the paper. Based on the reviews and your insights, I have decided to adjust my rating to marginal acceptance. The paper is interesting and presents an innovative approach to recovering deep network structures. While the practicality of the threat model is concerning, the paper provides insights that are relevant to the safety-critical applications community using ML.