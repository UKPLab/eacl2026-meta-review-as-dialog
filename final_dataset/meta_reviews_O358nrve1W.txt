Meta-reviewer: Hello, can you provide me with a summary of the paper's main idea and methodology?

Dialogue agent: Of course. The paper proposes a method called Neurally Guided Genetic Programming for Turing Complete Programming by Example. The core idea is to use neural networks to provide starting hints to a program synthesizer based on genetic programming. Specifically, the network predicts one or two lines that must be present in the desired program given the input-output examples for the task. These lines are used to initialize the GP process instead of an empty program. The end-to-end system works as follows: 1) Start with a subset of easy tasks. Identify 10 best code fragments that, if provided, increase the find rate of GP (via brute force enumeration of all fragments). 2) Generate a synthetic train/test set for the classification problem "IO -> Fragment Presence" for each fragment. 3) Train a classification NN for each fragment. 4) For all tasks (including the ones from step 1), use the trained NNs to select the code fragments to provide as hints to GP. Measure the find rate of GP.

Meta-reviewer: Thank you. What are the strengths and weaknesses of the paper according to the reviewers?

Dialogue agent: Reviewer 1 found the main idea promising, but had some concerns about the experimental setup and presentation clarity. Reviewer 2 had two objections: the experiments seemed small-scale and did not highlight the raw performance and general applicability, and there is prior work in the conceptual neighborhood that the authors did not compare their method against. Reviewer 3 found the methodology quite substantial, but had concerns about the manual efforts required for generating the training set, unclear experimentation descriptions, missing baselines, and practicality issues.

Meta-reviewer: I see. How confident are the reviewers about their ratings?

Dialogue agent: Reviewer 1 rated the paper as marginally below the acceptance threshold with a confidence level of 5, meaning that the reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature. Reviewer 2 also rated the paper as marginally below the acceptance threshold with a confidence level of 4, meaning that the reviewer is confident but not absolutely certain that the evaluation is correct. Reviewer 3 rated the paper as ok but not good enough for acceptance with a confidence level of 4, meaning that the reviewer is confident but not absolutely certain that the evaluation is correct.

Meta-reviewer: Based on the reviewers' feedback, I am concerned about the paper's scalability, experimental setup, and missing comparisons with the prior work. However, I am intrigued by the paper's core idea and methodology. Therefore, I would like to know more about the confidence levels of the reviewers' ratings. Can you provide me with more information about the reviewers' expertise and qualifications?

Dialogue agent: Reviewer 1 is an expert with a confidence level of 5, meaning that the reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature. Reviewers 2 and 3 are confident with a confidence level of 4, meaning that they are knowledgeable and experienced but not infallible. 

Meta-reviewer: Thank you. Based on the reviewers' feedback and their qualifications, I am inclined to reject the paper due to concerns about scalability, experimental setup, and missing comparisons with the prior work. However, I appreciate the core idea and methodology of the paper, and I encourage the authors to address the reviewers' concerns and resubmit the revised version in the future.