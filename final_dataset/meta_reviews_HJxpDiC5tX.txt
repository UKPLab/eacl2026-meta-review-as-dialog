Meta-Reviewer: Thank you for providing me with these reviews for the paper on Large-Scale Visual Speech Recognition. Review 1 seems to have some concerns about the technical novelty and the need for additional experiments to show the improvement is not just due to having a larger model and more data. Review 2 is highly critical of the paper, questioning the novelty and leaving some important questions unanswered. Meanwhile, Review 3 is very positive, praising the authors' meticulous work and stating that the dataset and systems built give state-of-the-art performance. Based on this feedback, could you summarize the key contributions of this paper and address the concerns raised by Review 1 and 2?

Dialogue Agent: The paper presents a large-scale visual speech recognition system that achieves state-of-the-art performance and a detailed technical pipeline for creating a very large visual speech recognition dataset, which is a valuable contribution to the community. However, as Review 1 points out, there may be concerns about the technical novelty of the paper. While all of the techniques employed have been proposed before, the paper does demonstrate how they can be combined to achieve state-of-the-art performance. As for Review 2's questions, the authors did not use a viseme dictionary as they found that using phonemes provided better performance. The million-word phoneme vocabulary was generated using a grapheme-to-phoneme conversion tool, and error analysis was provided in Table 1 of the paper.

Meta-Reviewer: Thank you for addressing those issues. Review 2 also questioned the authors' claim of "production-grade word-level decoding techniques" and asked how their model is the first of its kind when Google has a similar model in production. Can you comment on that?

Dialogue Agent: While Google does have a similar model in production, the authors' model differs in its use of a deep learning-based phoneme recognition model. The paper does not claim to be the first to use those techniques in general, only the first to combine them in this specific way to achieve state-of-the-art performance. The claim of "production-grade" is based on the performance achieved on the dataset and may not necessarily mean the same as Google's approach.

Meta-Reviewer: Finally, Review 1 suggested some additional experiments to better understand the contribution of the different techniques used to achieve the results. Were these experiments conducted or discussed in the paper?

Dialogue Agent: While the paper did not conduct all of the suggested experiments, it did discuss the need for additional experiments to better understand the contribution of the different techniques and to address the concerns raised. The authors did conduct some experiments where they fixed various parameters and changed others, as suggested in Review 1. These experiments were discussed in the paper and showed the effect of each parameter on the performance. However, the authors did not conduct experiments comparing their proposed system trained on LRS3-TED against TM-seq2seq as suggested in Review 1.