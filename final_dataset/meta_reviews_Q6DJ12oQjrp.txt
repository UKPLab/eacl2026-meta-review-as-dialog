Meta-reviewer: Hello, Dialogue agent. I am a meta-reviewer and I have been assigned to review the paper titled "Sparse Interaction Additive Networks via Feature Interaction Detection and Sparse Selection." Can you tell me more about the paper based on the reviews that you have received?

Dialogue Agent: Certainly! Based on the reviews we have received, the paper proposes a new method called Sparse Interaction Additive Networks (SIANs) that can effectively scale up interpretable additive models while making their training tractable. The paper presents a solution for selecting higher-order interactions for generalized additive models, and extensive experiments demonstrate reasonable performance on various classification and regression datasets.

Meta-reviewer: Can you talk about the strengths and weaknesses of the paper based on the reviews?

Dialogue Agent: According to review 1, the paper is well-written and the goal of the paper is well-motivated. However, the reviewer suggests that the paper could be improved by incorporating a discussion or empirical comparison between the interpretability of DNNs and SIANs. Reviewer 2 notes that the paper is well-organized and easy to follow, and provides sufficient implementation details for reproducibility. However, there are concerns about how to effectively choose the feature intersection order used in SIAN for better performance. Reviewer 3 highlights the sound solution for addressing efficiency issues and extensive experiments on various datasets. However, the reviewer notes that the paper has relatively weak direct technical novelty, as it mostly combines Archipelago and generalized additive models.

Meta-reviewer: Based on the reviews, it seems as though the paper has technical solidity and moderate-to-high impact. Can you provide more information about the ratings and the level of confidence for the reviews?

Dialogue Agent: Certainly! The ratings for all three reviews were "Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations." As for the level of confidence, Reviewer 1 had a confidence level of 3, indicating that they are fairly confident in their assessment, but it is possible that they did not understand some parts of the submission or that they are unfamiliar with some pieces of related work. Reviewer 2 had a confidence level of 2, indicating that they are willing to defend their assessment, but it is quite likely that they did not understand the central parts of the submission or that they are unfamiliar with some pieces of related work. Reviewer 3 had a confidence level of 3, indicating that they are fairly confident in their assessment, but it is possible that they did not understand some parts of the submission or that they are unfamiliar with some pieces of related work. Math and other details were not carefully checked for all three reviews.